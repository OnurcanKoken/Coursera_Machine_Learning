{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Activation_Custom_Layers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNyBVb3sxKn4IQrjlntuDSO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OnurcanKoken/Coursera_Machine_Learning/blob/main/Custom_Models_Layers_and_Loss_Functions_with_TensorFlow/Activation_Custom_Layers_Week3_Lab3/Activation_Custom_Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ppQS73oOSHS"
      },
      "source": [
        "# Ungraded Lab: Activation in Custom Layers\n",
        "\n",
        "In this lab, we extend our knowledge of building custom layers by adding an activation parameter. The implementation is pretty straightforward as you'll see below.\n",
        "\n",
        "Date: 19th of May, 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDCcTG0EOTDF"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KxGN_u9OUOz"
      },
      "source": [
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCWS54hjOVPL"
      },
      "source": [
        "## Adding an activation layer\n",
        "\n",
        "To use the built-in activations in Keras, we can specify an `activation` parameter in the `__init__()` method of our custom layer class. From there, we can initialize it by using the `tf.keras.activations.get()` method. This takes in a string identifier that corresponds to one of the [available activations](https://keras.io/api/layers/activations/#available-activations) in Keras. Next, you can now pass in the forward computation to this activation in the `call()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72-9tOthOXLa"
      },
      "source": [
        "class SimpleDense(Layer):\n",
        "\n",
        "    # add an activation parameter\n",
        "    def __init__(self, units=32, activation=None):\n",
        "        super(SimpleDense, self).__init__()\n",
        "        self.units = units\n",
        "        \n",
        "        # define the activation to get from the built-in activation layers in Keras\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        w_init = tf.random_normal_initializer()\n",
        "        self.w = tf.Variable(name=\"kernel\",\n",
        "            initial_value=w_init(shape=(input_shape[-1], self.units),\n",
        "                                 dtype='float32'),\n",
        "            trainable=True)\n",
        "        b_init = tf.zeros_initializer()\n",
        "        self.b = tf.Variable(name=\"bias\",\n",
        "            initial_value=b_init(shape=(self.units,), dtype='float32'),\n",
        "            trainable=True)\n",
        "        super().build(input_shape)\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \n",
        "        # pass the computation to the activation layer\n",
        "        return self.activation(tf.matmul(inputs, self.w) + self.b)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8ZKK2rZOYO1"
      },
      "source": [
        "We can now pass in an activation parameter to our custom layer. The string identifier is mostly the same as the function name so 'relu' below will get `tf.keras.activations.relu`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0_OvbCLOZpV",
        "outputId": "2cfbaa5c-3da3-4c8c-d2da-a0bea9f372d0"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    # custom layer\n",
        "    SimpleDense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4831 - accuracy: 0.8591\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1499 - accuracy: 0.9554\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1135 - accuracy: 0.9649\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0896 - accuracy: 0.9729\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0721 - accuracy: 0.9774\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.9772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07581514865159988, 0.9771999716758728]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTAeUZT3Pcko"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}